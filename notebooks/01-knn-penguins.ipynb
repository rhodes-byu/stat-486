{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0277099e",
   "metadata": {},
   "source": [
    "# Palmer Penguins Dataset: Overview\n",
    "\n",
    "The Palmer Penguins dataset contains data about three species of penguins observed in the Palmer Archipelago, Antarctica. The dataset was collected by Dr. Kristen Gorman and the Palmer Station LTER (Long Term Ecological Research) Program. It serves as a popular alternative to the Iris dataset for data exploration, statistical analysis, and machine learning practice due to its richer set of features and categorical variables.\n",
    "\n",
    "Dataset Features:\n",
    "\n",
    "The dataset consists of 344 rows and 7 columns. The columns are:\n",
    "\n",
    "\t1.\tspecies: Categorical feature indicating the penguin species (Adélie, Chinstrap, Gentoo).\n",
    "\t2.\tisland: Categorical feature representing the island where the penguin was observed (Biscoe, Dream, Torgersen).\n",
    "\t3.\tbill_length_mm: Continuous numerical feature representing the length of the penguin’s bill (in millimeters).\n",
    "\t4.\tbill_depth_mm: Continuous numerical feature representing the depth of the penguin’s bill (in millimeters).\n",
    "\t5.\tflipper_length_mm: Continuous numerical feature representing the penguin’s flipper length (in millimeters).\n",
    "\t6.\tbody_mass_g: Continuous numerical feature representing the penguin’s body mass (in grams).\n",
    "\t7.\tsex: Categorical feature indicating the penguin’s sex (male or female), though some entries are missing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa26f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = sns.load_dataset('penguins')\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfefcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target from features\n",
    "X = data.drop(columns=['species'])\n",
    "X = pd.get_dummies(X)\n",
    "y = data['species']\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd52ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split int training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1990) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd495f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fit your model!\n",
    "\n",
    "k = 5\n",
    "metric = 'euclidean'\n",
    "knn = KNeighborsClassifier(n_neighbors = k, metric = metric)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def54a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model validation\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test) * 100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb615f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attempt 2: Rescaling the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = knn.predict(X_test_scaled)\n",
    "\n",
    "accuracy = np.sum(y_pred_scaled == y_test) / len(y_test) * 100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b54f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns = X_train.columns, index = X_train.index)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "\n",
    "sns.scatterplot(x = X_train['bill_length_mm'], \n",
    "                y = X_train['body_mass_g'], hue = y_train, ax = ax[0])\n",
    "ax[0].set_title('Training: original features')\n",
    "\n",
    "sns.scatterplot(x = X_train_scaled['bill_length_mm'], \n",
    "                y = X_train_scaled['body_mass_g'], hue = y_train, ax = ax[1])\n",
    "ax[1].set_title('Training: scaled features')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b30727",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (10, 5))\n",
    "\n",
    "# ensure X_test_scaled is a DataFrame with the same columns/index as X_test\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns = X_test.columns, index = X_test.index)\n",
    "\n",
    "sns.scatterplot(x = X_test['bill_length_mm'], \n",
    "                y = X_test['body_mass_g'], hue = y_pred, ax = ax[0])\n",
    "ax[0].set_title('Predicted species (original features)')\n",
    "\n",
    "sns.scatterplot(x = X_test_scaled['bill_length_mm'], \n",
    "                y = X_test_scaled['body_mass_g'], hue = y_pred_scaled, ax = ax[1])\n",
    "ax[1].set_title('Predicted species (scaled features)')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce17eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['bill_length_mm', 'body_mass_g']\n",
    "\n",
    "# raw (unscaled) training data for the two features\n",
    "Xr_train = X_train[features].values\n",
    "Xr_test = X_test[features].values\n",
    "\n",
    "# scaled training data for the two features\n",
    "Xs_train = X_train_scaled[features].values\n",
    "Xs_test = X_test_scaled[features].values\n",
    "\n",
    "# prepare mesh grid in the original feature space\n",
    "all_points = np.vstack([Xr_train, Xr_test])\n",
    "x_min, x_max = all_points[:, 0].min() - 1.0, all_points[:, 0].max() + 1.0\n",
    "y_min, y_max = all_points[:, 1].min() - 200.0, all_points[:, 1].max() + 200.0\n",
    "\n",
    "h_x = 0.2\n",
    "h_y = 25.0\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h_x), np.arange(y_min, y_max, h_y))\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# fit raw KNN\n",
    "knn_raw = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "knn_raw.fit(Xr_train, y_train)\n",
    "\n",
    "Zr = knn_raw.predict(grid_points)\n",
    "\n",
    "# fit scaled KNN: need to scale the grid points for the same two features\n",
    "# find indices of the two features in the original scaler (fitted on X_train)\n",
    "col_indices = [list(X_train.columns).index(f) for f in features]\n",
    "means = scaler.mean_[col_indices]\n",
    "scales = scaler.scale_[col_indices]\n",
    "grid_points_scaled = (grid_points - means) / scales\n",
    "\n",
    "knn_scaled = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "knn_scaled.fit(Xs_train, y_train)\n",
    "\n",
    "Zs = knn_scaled.predict(grid_points_scaled)\n",
    "\n",
    "# convert class labels to integers for plotting\n",
    "classes = np.unique(y_train)\n",
    "label_to_int = {label: i for i, label in enumerate(classes)}\n",
    "Zr_int = np.vectorize(label_to_int.get)(Zr).reshape(xx.shape)\n",
    "Zs_int = np.vectorize(label_to_int.get)(Zs).reshape(xx.shape)\n",
    "y_test_int = y_test.map(label_to_int)\n",
    "\n",
    "cmap_light = ListedColormap(['#FFEEEE', '#EEFFEE', '#EEEEFF'])\n",
    "cmap_points = ListedColormap(['#FF0000', '#00AA00', '#0000FF'])\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# left: raw features decision boundary\n",
    "axs[0].contourf(xx, yy, Zr_int, cmap=cmap_light, alpha=0.6)\n",
    "sc = axs[0].scatter(Xr_test[:, 0], Xr_test[:, 1], c=y_test_int, cmap=cmap_points, edgecolor='k', s=50)\n",
    "axs[0].set_title('KNN decision boundary (raw features)')\n",
    "axs[0].set_xlabel('bill_length_mm')\n",
    "axs[0].set_ylabel('body_mass_g')\n",
    "\n",
    "# right: scaled features decision boundary (background plotted in original feature axes)\n",
    "axs[1].contourf(xx, yy, Zs_int, cmap=cmap_light, alpha=0.6)\n",
    "axs[1].scatter(Xr_test[:, 0], Xr_test[:, 1], c=y_test_int, cmap=cmap_points, edgecolor='k', s=50)\n",
    "axs[1].set_title('KNN decision boundary (scaled features)')\n",
    "axs[1].set_xlabel('bill_length_mm')\n",
    "axs[1].set_ylabel('body_mass_g')\n",
    "\n",
    "# legend with class names\n",
    "handles = []\n",
    "for i, cls in enumerate(classes):\n",
    "    handles.append(plt.Line2D([0], [0], marker='o', color='w', label=cls,\n",
    "                              markerfacecolor=cmap_points(i), markersize=8, markeredgecolor='k'))\n",
    "axs[1].legend(handles=handles, title='species', loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
